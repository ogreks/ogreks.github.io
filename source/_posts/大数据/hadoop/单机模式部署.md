---
title: Hadoop 单机安装
date: 2020-01-13 10:45:08
categories:
 - Hadoop
 - 部署和管理
tags:
 - hadoop
 - 单机模式
cover: https://s2.ax1x.com/2020/01/14/lLAWeH.jpg
---


## Hadoop 单机安装

### Hadoop 启动模式

Hadoop 集群有三种启动模式：

* 单机模式：默认情况下运行为一个单独机器上的独立 Java 进程，主要用于调试环境
* 伪分布模式：在单个机器上模拟成分布式多节点环境，每一个 Hadoop 守护进程都作为一个独立的 Java 进程运行
* 完全分布式模式：真实的生产环境，搭建在完全分布式的集群环境

### 用户及用户组 

需要添加用来运行Hadoop 进程的用户组 Hadoop 及用户 Hadoop  

***注意：没有linux 环境可以使用docker***  

可以使用下面的命令来查看已经创建好的 hadoop 用户和 uid 与 gid  

```
$ id hadoop
```

另外在 ***/etc/passwd*** 文件中也记录了用户的信息，使用下面的命令查看：  

```
$ tail -5 /etc/passwd
```

添加用户及用户组的步骤如下：  

创建用户 Hadoop   
```
$ sudo adduser hadoop
```

请按照提示输入 hadoop 用户的密码，例如密码设定为 ***hadoop*** 。  


将 hadoop 用户添加进 sudo 用户组  

```
$ sudo usermod -G sudo hadoop
```

### 安装及配置以来的软件包  

Hadoop 的 运行需要JDK， 同时还应配置 SSH 免密码登录  

> 关于配置Java的环境变量，请自行搜索教程  

### 配置SSH免密码登录  

切换到 hadoop 用户， hadoop 用户时密码为 hadoop。 后续步骤都将在 hadoop 用户的环境中执行。  

```
// 切换 hadoop 用户
su hadoop
```


配置 ssh 环境免密码登录。  

在 ***/home/hadoop*** 目录下执行下面的命令  

```
// 切换到根目录
$ cd ~ 

// 生成秘钥对
$ ssh-keygen -t rsa

// 一路回车保持默认配置即可
```

对于秘钥对的设置，保持迷人，等到执行完成后，秘钥对就生成好了（一般存放于 ***~/.ssh/*** 目录中）  

```
// 将公钥写入验证文件中
$ cat .ssh/id/rsa.pub >> .ssh/authorized_keys

// 修改文件的权限为 600 
$ chmod 600 .ssh/authorized_keys
```

验证登录本机是否还需要密码，第一次需要密码以后不需要密码就可以登录  

```
// 仅需输入一次 hadoop 密码， 以后不需要输入  
$ ssh localhost
```

### 下载并安装 Hadoop

注意，本部分的操作都是在 hadoop 用户登录的环境中进行的。  

切换用户使用下面的命令。  

```
// 切换为 hadoop 用户  
$ su hadoop 

// 密码为 hadoop
```

#### 下载 Hadoop 2.6.0

> 本次演示为 hadoop 2.6.0 学习者可以安装其他版本 具体安装步骤请参考官网  

Hadoop 的下载比较缓慢，为了方便大家下载，推荐大家搜索如何 使用 阿里云的镜像  

```
// 进入家目录 /home/hadoop
$ cd ~

$ wget 阿里云镜像地址  
```

#### 解压并安装 

```
$ tar zxvf hadoop-2.6.0.tar.gz
```

请耐心等待解压完成  

安装之前还需要删除之前的遗留文件，如果出现无此文件夹的提示， 说明没有遗留文件。  

```
// 删除原本遗留的 hdfs 文件夹
$ rm -r /home/hadoop/hdfs
```

然后再进行安装工作。  

```
// 复制所需文件  
$ mv hadoop-2.6.0 /home/hadoop/hdfs

// 将文件夹权限设置为 777
$ chmod 777 /home/hadoop/hdfs
```

#### 配置 Hadoop  

```
$ vim /home/hadoop/.bashrc
```

在 ***/home/hadoop/.bashrc*** 文件末尾添加下列内容：   

> 下面配置中 以 ***#*** 开头的是注释，无需输入  

```
#HADOOP START
export HADOOP_HOME=/home/hadoop/hdfs
export JAVA_HOME=/usr/lib/jvm/java-8-oracle
#HADOOP END
```

在 ***/home/hadoop/.bashrc*** 文件中 PATH 路径更改 HADOOP 相关内容：  

```
export PATH=/usr/local/sbin:/usr/local/bin/:/usr/bin:/usr/sbin:/sbin:/bin:/home/hadoop/hdfs/bin:/home/hadoop/hdfs/sbin
```

保存退出后，激活新加的环境变量  

```
$ source ~/.bashrc
```

至此，Hadoop 单机模式安装完成，可以通过下述步骤的测试来验证安装是否成功。  

### 验证测试

创建输入的数据，暂时采用 ***/etc/protocols*** 文件作为测试  

```
# 进入到 Hadoop 的目录
$ cd /home/hadoop/hdfs

# 新建一个 input 文件夹
$ mkdir input

# 复制文件到 input 中
$ cp /etc/protocols ./input/
```

执行 Hadoop WordCount 应用（词频统计）  

```
$ hadoop jar \
  /home/hadoop/hdfs/share/hadoop/mapreduce/sources/hadoop-mapreduce-examples-2.6.0-sources.jar   \
  org.apache.hadoop.examples.WordCount input output
```

### 参考文档

* [http://hadoop.apache.org/docs/r2.6.0/hadoop-project-dist/hadoop-common/SingleCluster.html](http://hadoop.apache.org/docs/r2.6.0/hadoop-project-dist/hadoop-common/SingleCluster.html)

* [http://www.cnblogs.com/kinglau/p/3794433.html](http://www.cnblogs.com/kinglau/p/3794433.html)