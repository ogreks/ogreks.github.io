---
title: Hadoop 伪分布式配置部署
date: 2020-01-13 11:45:08
categories:
 - Hadoop
 - 部署和管理
tags:
 - hadoop
 - 伪分布式
cover: https://s2.ax1x.com/2020/01/14/lLAWeH.jpg
---


## Hadoop 伪分布式配置部署

> 在阅读本章节之前，请确定你已经阅读过，[Hadoop 单机版部署](/2020/01/13/hadoop-单机模式部署-2020-01-13/) 并存在环境  

### Hadoop 伪分布式模式配置  

> 再次提醒 当前环境 必须是 您在阅读 ***Hadoop 单机版部署*** 后部署的环境  

### 修改 core-site.xml

这里我们需要修改 ***core-site.xml***, 使用下面的命令调用 Vim 编辑器来编辑文件。  

```
$ cd /home/hadoop/hdfs/etc/hadoop

$vim ./core-site.xml
```

先说一下常用配置项：  

* ***fs.defaultFS***

***fs.defaultFS*** 是默认的HDFS 路径。 当有多个 HDFS 集群同时工作时，用户在这里指定默认HDFS 集群， 该值来自于 ***hdfs-site.xml*** 中的配置。  

* ***fs.default.name*** 

***fs.default.name*** 是一个描述集群中 NameNode 节点的 URI(包括协议、主机名称、端口号)， 集群里面的每一台机器都需要知道 NameNode 的地址。 DataNode 节点会现在 NameNode 上注册， 这样他们的数据才可以被使用。 独立的客户端程序通过这个 URI 跟 DataNode 交互， 以取得文件的块列表。  

* ***hadoop.tmp.dir***  

***hadoop.tmp.dir*** 是hadoop 文件系统依赖的基础配置，很多路径都依赖它。如果 ***hdfs-site.xml*** 中不配置namenode 和 datanode 的存放位置，默认就放在 ***/tmp/hadoop-${user.name}*** 这个路径中。  

更多说明请参考 [core-default.xml](http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/core-default.xml), 包含配置文件所有配置项的说明和默认值。  

配置好以后的文件内容如下：  

```
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/home/hadoop/tmp</value>
   </property>
</configuration>
```

### 修改 hdfs-site.xml

这里我们要修改的是 ***hdfs-site.xml***, 使用下面的命令调用 Vim 编辑器来编辑文件  

```
$ cd /home/hadoop/hdfs/etc/hadoop/

$ vim ./hdfs-site.xml
```

常用配置项说明：  

* ***dfs.replication***

***dfs.replication*** 决定着系统里面的文件块的数据备份个数。对于一个实际的应用，它应该被设为 3 (这个数字并没有上限,但更多的备份可能并没有作用,而且会占用更多的空间)。 少于三个备份，可能会影响到数据的可靠性（系统故障时，也许会造成数据丢失）  

* ***dfs.data.dir***  

***dfs.data.dir*** 这是 DataNode 节点被指定要存储数据的本地文件系统路径。 DataNode 节点上的这个路径没有必要完全相同，因为每台机器的环境很可能是不一样的。但如果每台机器上的这个路径都是统一配置的话，会使工作变得简单一些。 默认的情况下，它的值为 ***file://${hadoop.tmp.dir}/dfs/data*** 这个路径只能用于测试的目的， 因为它很可能会丢失掉一些数据。所以这个值最好还是被覆盖。  

* ***dfs.name.dir***  

***dfs.name.dir*** 是NameNode节点存储 hadoop 文件系统信息的本地系统路径。 这个值只对 NameNode 有效， DataNode 并不需要使用 到它。上面对于 ***/temp*** 类型的警告， 同样也适用于这里。 在实际应用中，它最好被覆盖掉。  

更多说明请参考 [hdfs-default.xml](http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml), 包含配置文件所有配置项的说明和默认值  

配置好以后的文件内容如下：  

```
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
</configuration>
```

### 修改 mapred-site.xml

使用下面的命令先将默认文件复制一份过来，然后调用 Vim 编辑器进行编辑。  

```
$ cd /home/hadoop/hdfs/etc/hadoop/

$ cp ./mapred-site.xml.template ./mapred-site.xml

$ vim ./mapred-site.xml
```

常用配置项说明：  

* ***mapred.job.tracker***：JobTracker 的主机（或者 IP）和端口。
更多说明请参考[mapred-default.xml](http://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml)，包含配置文件所有配置项的说明和默认值  

配置好以后的文件内容如下：  

```
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>
```

### 修改 yarn-site.xml

编辑 ***yarn-site.xml*** 文件   

```
$ cd /home/hadoop/hdfs/etc/hadoop

$ vim ./yarn-site.xml
```

常用配置项说明：  

* ***yarn.nodemanager.aux-services*** 通过该配置，用户可以自定义一些服务  

更多说明请参考[yarn-default.xml](http://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-common/yarn-default.xml)，包含配置文件所有配置项的说明和默认值  

配置好以后的文件内容如下：

```
<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>

</configuration>
```

### 修改 hadoop-env.sh

```
$ cd /home/hadoop/hdfs/etc/hadoop/

$ sudo vim ./hadoop-env.sh
```

修改 JAVA_HOME 如下：  

```
export JAVA_HOME=/usr/lib/jvm/java-8-oracle
export HADOOP_CONF_DIR=/home/hadoop/hdfs/etc/hadoop
```

这样简单的伪分布式就配置好了。  

### 格式化 HDFS 文件系统  

在使用 hadoop 前，必须格式化一个全新的 HDFS 安装，通过创建存储目录和 NameNode 持久化数据结构的初始版本，格式化过程创建了一个空的文件系统。  

由于 NameNode 管理文件系统的元数据，而 DataNode 可以动态的加入或离开集群，因此这个格式化过程并不涉及 DataNode。同理，用户也无需关注文件系统的规模。  

集群中 DataNode 的数量决定着文件系统的规模。DataNode 可以在文件系统格式化之后的很长一段时间内按需增加。  

使用下面的命令进行给格式化。  

```
$ cd ~

$ hadoop namenode -format
```

### Hadoop 集群启动 

#### 启动 hdfs 守护进程 

启动 HDFS 守护进程： 分别启动 NameNode 和 DataNode  

```
$ start-dfs.sh
```

输出如下（可以看出分别启动了 namenode,datanode,secondarynamenode,因为我们没有配置 secondarynamenode,所以地址为 0.0.0.0）：  

#### 启动 yarn
使用如下命令启动 ResourceManager 和 NodeManager：  

```
$ start-yarn.sh
```

#### 检查是否运行成功

打开浏览器  

* 输入： ***http://localhost:8088*** 进入 ResourceManager 管理页面 

* 输入： ***http://localhost:50070*** 进入 HDFS 页面

#### 可能出现的问题及调试方法

启动伪分布式之后， 如果活跃节点显示为零，说明伪分布没有真正的启动。  

原因时有的时候数据结构出现问题会造成无法启动 datanode。 如果使用 ***hadoop namenode -format*** 重新格式化仍然无法正常启动，原因时 ***/tmp*** 中的文件没有清楚，则需要先清除 ***/tmp/hadoop/\**** 再执行格式化，即可解决 hadoop datanode 无法启动的问题。  

具体步骤如下所示：   

```
# 删除 hadoop:/tmp
$ hadoop fs -rmr /tmp

# 停止 hadoop
$ stop-all.sh

# 删除 /tmp/hadoop*
$ rm -rf /tmp/hadoop*

# 格式化
$ hadoop namenode -format

# 启动 hadoop
$ start-all.sh
```

### 测试验证  

测试验证还是使用 之前的 WordCount。  

不同的是 ，这次使用了伪分布式模式。  使用了 hdfs ， 因此我们需要把文件拷贝到 hdfs 上去。  

首先创建相关文件夹  

```
$ hdfs dfs -mkdir -p /user/hadoop/input
```

#### 创建输入的数据  

这里我们采用 ***/etc/protocols*** 文件作为输入的数据进行测试、现将文件拷贝到 hdfs 上：  

```
# 上传
$ hdfs dfs -put /etc/protocols /user/hadoop/input

# 查看是否上传成功
$ hdfs dfs -ls /user/hadoop/input
```

#### 执行 Hadoop WordCount 应用（词频统计）  

如果存在上一次测试生成的output，由于hadoop 的安全机制，直接运行可能会报错，所以请手动删除上一次生成的 output 文件夹  

```
$ rm -rf /home/hadoop/hdfs/output/
```

然后运行词频统计程序

```
$ hadoop jar   \
  /home/hadoop/hdfs/share/hadoop/mapreduce/sources/hadoop-mapreduce-examples-2.6.0-sources.jar   \
  org.apache.hadoop.examples.WordCount   \
  /user/hadoop/input output
```

#### 查看生成的单词统计数据

耐心等待前面的词频统计命令结束后，输入下面的命令查看结果：  

```
$ hdfs dfs -cat /user/hadoop/output/*
```

### 关闭服务

* 关闭 HDFS 守护进程

```
$ stop-dfs.sh
```

* 关闭 yarn 

```
$ stop-yarn.sh
```


### 参考文档

[http://www.cnblogs.com/kinglau/p/3796164.html](http://www.cnblogs.com/kinglau/p/3796164.html)